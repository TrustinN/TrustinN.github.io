%! TeX root = /Users/trustinnguyen/Downloads/Berkeley/Math/Math143/Homework/Math143Hw4/Math143Hw4.tex

\documentclass{article}
\usepackage{/Users/trustinnguyen/.mystyle/math/packages/mypackages}
\usepackage{/Users/trustinnguyen/.mystyle/math/commands/mycommands}
\usepackage{/Users/trustinnguyen/.mystyle/math/environments/article}

\title{Math143Hw4}
\author{Trustin Nguyen}

\begin{document}

    \maketitle

\reversemarginpar

\textbf{Exercise 1}: Let $R$ be an integral domain and let
    \begin{equation*}
        \mathop{Frac}(R) = \{a / b : a, b \in R, b \neq 0\}/ \sim 
    \end{equation*}
where $a/b \sim  c/ d$ if $ad = bc \in R$.
    \begin{itemize}
        \item [(a)] Prove that the map $\iota: R \rightarrow \mathop{Frac}(R)$ that sends $a \mapsto a/1$ is injective.
            \begin{proof}
                Suppose that we have $\iota(r_{1}) = \iota(r_{2})$. Then $r_{1}/1 = r_{2}/1$. But by the equivalence relation, we have that $1 \cdot r_{1} = 1 \cdot r_{2}$ which means that $r_{1} = r_{2}$. So the mapping is injective.
            \end{proof}

        \item [(b)] Prove that if $K$ is a field and $\varphi: R \rightarrow K$ is any homomorphism, then there exists a map $\beta: \mathop{Frac}(R) \rightarrow K$ such that $\varphi  = \beta \circ \iota$. 
            \begin{proof}
                For any homomorphism $\varphi$, we can say that
                    \begin{equation*}
                        \varphi(r_{i}) = k_{i}
                    \end{equation*}
                for $r_{i} \in R, k_{i} \in K$. Then define the mapping:
                    \begin{equation*}
                        \beta(r_{i}/1) = k_{i} = \varphi(r_{i})
                    \end{equation*}
                We will show that $\beta$ is a homomorphism:
                    \begin{align*}
                        \beta(r_{i}/1)\beta(r_{j}/1) &= \varphi(r_{i})\varphi(r_{j}) \\
                                                     &= \varphi(r_{i}r_{j})          \\
                                                     &= \beta(r_{i}r_{j}/1)            
                    \end{align*}
                and for addition:
                    \begin{align*}
                        \beta(r_{i}/1) + \beta(r_{j}/1) &= \varphi(r_{i}) + \varphi(r_{j}) \\
                                                        &= \varphi(r_{i} + r_{j})          \\
                                                        &= \beta((r_{i} + r_{j})/1)          
                    \end{align*}
                since 
                    \begin{equation*}
                        \beta(\iota(r_{i})) = \beta(r_{i}/1) = \varphi(r_{i})
                    \end{equation*}
                we are done.
            \end{proof}
    \end{itemize}

\textbf{Exercise 2}: 
    \begin{itemize}
        \item [(a)] Suppose $\psi : k \rightarrow R$ is a ring homomorphism with $k$ a field. Prove that $\psi$ is either injective or the zero map.
            \begin{proof}
                Suppose that $\psi$ is not injective. We will prove that it is the zero map. Then we have a nontrivial kernel with an element $g \in K$. Then $(g)$ generates the entire field $k$. But $g \mapsto 0$. So we say that for $k \in K$ $ag = k$ for some $a \in K$ and $\psi(ag) = 0$. So we are done.
            \end{proof}

        \item [(b)] Does there exist a surjective map $k[x_{1}, \ldots , x_{n}] \rightarrow k(y)$? Give an example explain why none exists. (You may quote results from class.) 
    \end{itemize}

\textbf{Exercise 3}: Practice with quotients:
    \begin{itemize}
        \item [(a)] Let $k$ be any field and $f \in k[x]$ a polynomial of degree $n> 0$. Show that images of $1, x, \ldots , x^{n - 1}$ in $k[x]/(f)$ form a basis for $k[x]/(f)$ as a vector space over $k$. 
            \begin{proof}
                Let $f = a_{d}x^{d} + a_{d - 1}x^{d - 1} + \cdots  + ax + 1$. We know that every polynomial in $k[x]/(f)$ is of degree $< d$, since otherwise, we can use the substitution:
                    \begin{equation*}
                        x^{d} = -a_{d}^{-1}(a_{d - 1}x^{d - 1} + \cdots +ax + 1)
                    \end{equation*}
                Since any polynomial of degree $< d$ can be written as a linear combination of $1, x, \ldots , x^{n - 1}$, then $1, x, \ldots , x^{n - 1}$ generate $k[x]/(f)$. Now suppose that 
                    \begin{equation*}
                        K = k_{0} + k_{1}x + \cdots + k_{n - 1}x^{n - 1} = 0
                    \end{equation*}
                Then $K \in (f)$ but $K$ has degree $<  d$ so it must be $0 \in (f)$. But the polynomial $K$ as a degree $\leq n - 1$ has at most $n - 1$ roots. Therefore, it cannot have degree $\geq 0$. So all coefficients $k_{i} = 0$ which shows linear independence.
            \end{proof}

        \item [(b)] Let $I \subseteq k[x, y]$ be the ideal generated by monomials of degree $d$
            \begin{equation*}
                I = (\{x^{i}y^{j} : i + j = d\})
            \end{equation*}
        What is the dimension of $k[x, y]/I$?
            \begin{proof}
                We can create an array of such $x, y$ pairs:
                    \begin{align*}
                        \begin{array}{ c c c c c }
                            (0, 0)  & (1, 0)  & (2, 0)  & \cdots  & (d, 0)  \\
                            (0, 1)  & (1, 1)  & (2, 1)  & \cdots  & (d, 1)  \\
                            (0, 2)  & (1, 2)  & (2, 2)  & \cdots  & (d, 2)  \\
                            \vdots  & \vdots  & \vdots  & \ddots  & \vdots  \\
                            (0, d)  & (1, d)  & (2, d)  & \cdots  & (d, d)    
                        \end{array}
                    \end{align*}
                If we draw a line through the diagonal that goes through $(d, 0)$ and $(0, d)$, we notice that all polynomials denoted by those points will lie in $I$. So the basis is given by everything above that diagonal to which there are $d(d - 1)/2$ elements.
            \end{proof}

        \item [(c)] (Optional, Extra Credit) Let $I \subseteq k[x_{1}, \ldots , x_{n}]$ be the ideal generated by monomials of degree $d$
            \begin{equation*}
                I = (\{x_{1}^{i_{1}} \cdots x_{n}^{i_{n}} : i_{1} + \cdots +i_{n} = d\}).
            \end{equation*}
        What is the dimension of $k[x_{1}, \ldots , x_{n}]/I$?

            \begin{proof}
                We can generalize the method used at the top:
                    \begin{align*}
                        \begin{array}{ c c c c c c c c }
                            1     &       &       &       &       &       &       &  \\
                            1     & 1     &       &       &       &       &       &  \\
                            1     & 2     & 1     &       &       &       &       &  \\
                            1     & 3     & 3     & 1     &       &       &       &  \\
                            1     & 4     & 6     & 4     & 1     &       &       &  \\
                            1     & 5     & 10    & 10    & 5     & 1     &       &  \\
                            1     & 6     & 15    & 20    & 15    & 6     & 1     &  \\
                            n = 0 & n = 1 & n = 2 & n = 3 & n = 4 & n = 5 & n = 6 &    
                        \end{array}
                    \end{align*}
                Note that the $n$ denotes the diagonal of the triangle. So on $n$ variables, we wish to compute the cumulative sum of the column, which is given by the values of the next column by the hockey stick theorem. So for degree $d$, we need to look at the $d - 1$-th row of that column. Therefore, we have a dimension of $\binom{n + d - 1}{d - 1}$. 
            \end{proof}
    \end{itemize}

\textbf{Exercise 4}: Suppose $P_{1}, \ldots , P_{m}$ are distinct points in $\mathbb{A}^{n}$. Prove that, for each $j$, there exists a polynomial $f$ such that $f(P_{i}) = 0$ if $i \neq j$ and $f(P_{j}) = 1$.
    \begin{proof}
        We can find a polynomial that kills one point. Let us do this for $P_{1}$. Notice that we have
            \begin{equation*}
                P_{1} = (q_{1}, q_{2}, \ldots , q_{n})
            \end{equation*}
        an $n$-tuple of $q_{i}$'s. Then taking the polynomial:
            \begin{equation*}
                f_{1}(x_{1}, \ldots , x_{n}) = (x_{1} - q_{1}) + \cdots + (x_{n} - q_{n})
            \end{equation*}
        will send this point to $0$. We can do this because the $q_{i}$ are in our underlying field. Since all $P_{i}$ are distinct, we can take for some $i \neq 1$, $P_{i}$ where $P_{i} - P_{1} \neq (0, 0, \ldots , 0)$. Therefore,
            \begin{equation*}
                f_{1}(P_{i}) = r \neq 0
            \end{equation*}
        So we can take an inverse:
            \begin{equation*}
                r^{-1}f_{1}(P_{i}) = 1
            \end{equation*}
        So we have found a polynomial $f_{1}$ that sends $P_{1} \mapsto  0$ and $P_{2} \mapsto 1$. In general, we can do this process for any two pairs of points. Suppose we are given points $P_{1}, \ldots , P_{m}$. Then we can find polynomials $f_{ij}$ such that:
            \begin{equation*}
                f_{ij}(P_{k}) = 
                    \begin{cases}
                        1 & \text{ if } k = i \\
                        0 & \text{ if } k = j
                    \end{cases}
            \end{equation*}
        Consider the product:
            \begin{equation*}
                f_{i} = \prod_{s \neq i \geq 1}^{m} f_{is}
            \end{equation*}
        Then $f_{i}(P_{s}) = 0$ for when $i \neq s$ since $f_{is}$ is a factor of $f_{i}$ and $f_{is}$ sends $P_{s}$ to $0$. Now when $i = s$, we have that:
            \begin{equation*}
                f_{i}(P_{s}) = f_{i1}(P_{s}) \cdot f_{i2}(P_{s}) \cdots f_{im}(P_{s})
            \end{equation*}
        But all $f_{ij}$ are equal to $1$, since $s = i$. So $f_{i}(P_{s}) = 1$. So we have found such a polynomial. We can repeat this process for the other points.
    \end{proof}

\textbf{Exercise 5}: Suppose $X \subseteq \mathbb{A}^{n}, Y \subseteq \mathbb{A}^{r}$ are algebraic sets and $\varphi : X \rightarrow Y$ and $\psi : Y \rightarrow Z$ are polynomial maps. 
    \begin{itemize}
        \item [(a)] Show that the composition $\psi \circ \varphi : X \rightarrow Z$ is a polynomial map.
            \begin{proof}
                If $\varphi$ is a polynomial map, that means that there exist $\varphi_{i}$ such that
                    \begin{equation*}
                        \varphi(p) = (\varphi_{1}(p), \varphi_{2}(p), \ldots , \varphi_{r}(p))
                    \end{equation*}
                And the same for $\psi$:
                    \begin{equation*}
                        \psi(p) = (\psi_{1}(p), \psi_{2}(p), \ldots , \psi_{s}(p))
                    \end{equation*}
                where $Z \subseteq \mathbb{A}^{s}$. So now we look at the composition $\psi \circ \varphi$:
                    \begin{equation*}
                        (\psi \circ \varphi)(p) = (\psi_{1}((\varphi_{1}(p), \ldots , \varphi_{r}(p))), \ldots, \psi_{s}((\varphi_{1}(p), \ldots , \varphi_{r}(p))))
                    \end{equation*}
                Since we have $\psi_{i} \in k[x_{1}, \ldots , x_{r}]$, we observe that $\psi_{i}(\varphi_{1}(p), \ldots , \varphi_{r}(p))$ is just the substitution of
                    \begin{align*}
                        x_{1} &=       \varphi_{1}(p) \\
                        x_{2} &=       \varphi_{2}(p) \\
                              &\vdots                 \\
                        x_{r} &=       \varphi_{r}(p)   
                    \end{align*}
                Indeed this gives us a polynomial in $k[x_{1}, \ldots , x_{n}]$ since each of the $\varphi_{i} \in k[x_{1}, \ldots , x_{n}]$. So we know there are polynomials $\pi \in k[x_{1}, \ldots , x_{n}]$ such that
                    \begin{equation*}
                        (\psi \circ \varphi)(p) = (\pi_{1}(p), \ldots , \pi_{s}(p))
                    \end{equation*}
            \end{proof}

        \item [(b)] Show that $(\psi \circ \varphi)^{*} = \varphi^{*} \circ \psi^{*}$. 
            \begin{proof}
                Suppose that $\psi : Y \rightarrow Z$ and $\varphi: X \rightarrow Y$. We just need to look at the action of $(\psi \circ \varphi)^{*}$ on $f$ and $\varphi^{*} \circ \psi^{*}$ on $f \in \Gamma(Z)$:
                    \begin{align*}
                        (\psi \circ \varphi)^{*}(f) &= f \circ (\psi \circ \varphi) & (\varphi^{*} \circ \psi^{*})(f) &= \varphi^{*}(f \circ \psi)    \\
                                                    &= f \circ \psi \circ \varphi   &                                 &= (f \circ \psi) \circ \varphi   
                    \end{align*}
                and indeed they are equal.
            \end{proof}
    \end{itemize}











\end{document}
