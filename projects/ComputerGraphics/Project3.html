<!DOCTYPE html><html lang="en"><head><meta charSet="UTF-8"/><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/d60010527bb7432e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-9edee2920554d0a5.js"/><script src="/_next/static/chunks/4bd1b696-9d53a45aeb6e92ca.js" async=""></script><script src="/_next/static/chunks/517-0c0d3409674fecb6.js" async=""></script><script src="/_next/static/chunks/main-app-794893a4f5078785.js" async=""></script><script src="/_next/static/chunks/173-ef7ddebb9db08982.js" async=""></script><script src="/_next/static/chunks/795-77b345457a57fcf5.js" async=""></script><script src="/_next/static/chunks/app/layout-98844b15afe18919.js" async=""></script><script src="/_next/static/chunks/970-ed0831cff5c90225.js" async=""></script><script src="/_next/static/chunks/app/projects/ComputerGraphics/Project3/page-42c309db0f3cd646.js" async=""></script><script src="/mathjax/es5/tex-chtml.js" id="MathJax-script" async=""></script><meta http-equiv="X-UA-Compatible" content="IE=edge"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div class="flex flex-col h-screen"><header class="items-stretch shadow-[0_5px_15px_rgba(0,0,0,0.35)]"><div class="md:hidden flex flex-row justify-between bg-black text-white relative z-50"><button type="button"></button></div><nav><ul class="flex justify-end bg-black text-center list-none "><li><a class="block p-0 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800 w-full h-full" href="/"><div class="flex justify-evenly items-center p-4">Home</div></a></li><li><a class="block p-0 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800 w-full h-full" href="/projects"><div class="flex justify-evenly items-center p-4">Projects</div></a></li><li><a class="block p-0 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800 w-full h-full" href="/education"><div class="flex justify-evenly items-center p-4">Education</div></a></li><li><a class="block p-0 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800 w-full h-full" href="/hobbies"><div class="flex justify-evenly items-center p-4">Hobbies</div></a></li><li><a class="block p-0 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800 w-full h-full" href="https://github.com/TrustinN"><div class="flex justify-center items-center w-full h-full"><div class="flex-grow bg-[url(/media/github.png)] bg-contain bg-no-repeat pl-[3.5rem] w-auto h-[70%] bg-center"> </div><div class="pr-4 pl-2">Github</div></div></a></li></ul></nav></header><div class="flex-grow"><div><div class="text-center text-black p-20 row-span-2 row-start-1 row-end-2 flex flex-col flex-nowrap justify-center items-center w-full"><h1>Project 3: Ray Tracing and Illumination</h1><p>(https://trustinn.github.io/projects/ComputerGraphics/Project3)</p></div><div class="mx-[5vw]"><div class="flex flex-row flex-nowrap justify-center relative"><div class="flex flex-col flex-grow max-w-[60rem]"><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Overview"><div><h2> Overview </h2><p>In this project, I have implemented methods simulate light in a scene and have explored ways to speed this up using a bounding volume hierarchy. From completing this assignment, I got a better grasp of how light interacts with objects and how different materials are rendered.</p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Ray Generation and Scene Intersection"><div><h2>Ray Generation and Scene Intersection </h2><p>To generate the camera rays for our scene, we normalize our image coordinates which we use to calculate the rays from the camera based on the vertical and horizontal field of views. The bottom left corner of the camera sensor is given by<span style="display:block">\begin{equation*} bl = \left(-\tan\frac{hFov}{2}, -\tan\frac{vFov}{2} \right) \end{equation*}</span>and for the top right, we get:<span style="display:block">\begin{equation*} tr = \left(\tan\frac{hFov}{2}, \tan\frac{vFov}{2} \right) \end{equation*}</span>So if we have a point <span style="display:inline">\(x, y\)</span> <!-- -->on the image, it would be a linear interpolation between the bottom left point and top right:<span style="display:block">\begin{equation*}bl + (x(tr - bl)[0], y(tr - bl)[1]) \end{equation*}</span></p><p>Next would be intersection the ray with various objects in the scene. The first intersection test would be with a triangle, and the method I used included solving a system of equations for the barycentric coordinates of a potential intersection point. This is known as the Moller-Trumbore algorithm, and we can recover the coefficients by solving the system:<span style="display:block">\begin{equation*}\begin{bmatrix}\mid &amp; \mid &amp; \mid \\-D &amp; (p_{2}-p_{1}) &amp; (p_{3}-p_{1}) \\ \mid &amp; \mid &amp; \mid \end{bmatrix}\begin{bmatrix} t \\ u \\ v \end{bmatrix} = r.o - p_{1} \end{equation*}</span>From this system, we get<!-- --> <span style="display:inline">\(t, u, v\)</span>, and for the last barycentric value, we can take<!-- --> <span style="display:inline">\(1 - u - v\)</span>. To check that the ray intersects the object, we require that<!-- --> <span style="display:inline">\(t &gt;= 0\)</span> and that there were no objects closer to the ray that the ray has already intersected with. So we also need<!-- --> <span style="display:inline">\(t &lt;= r.max_t\)</span>.</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="Triangle ray intersection render" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part1/CBempty.png"/><img alt="Coil render" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part1/CBcoil.png"/></div><p>We can also calculate the intersection of rays with sphere since we have the formula for both. The formula for a sphere is:<span style="display:block">\begin{equation*}\lVert v - s.c \rVert = s.r\end{equation*}</span>And for a ray:<span style="display:block">\begin{equation*} v = r.o + r.d \cdot t \end{equation*}</span>Then substituting in <span style="display:inline">\(v\)</span> into the sphere equation, we get a quadratic equation and can solve for<!-- --> <span style="display:inline">\(t\)</span> with the quadratic formula:<span style="display:inline">\begin{align*} a &amp;= dot(r.d, r.d)                       \\ b &amp;= 2 * dot(s.c - r.o, r.d)             \\ c &amp;= dot(s.c - r.o, s.c - r.o) - s.r^{2}   \end{align*} </span>We check for a nonnegative determinant to get solutions and here is the result of the ray intersection with a sphere:<div class="grid grid-cols-1 gap-4 items-center justify-center w-full mx-auto py-4 max-w-[30rem]"><img alt="Sphere ray intersection render" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part1/CBspheres.png"/></div></p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Bounding Volume Hierarchy"><div><h2> Bounding Volume Hierarchy </h2><p>In a bvh, we store objects and their bounding boxes. When we construct our tree out of these bounding boxes, we split the bounding boxes into a left and right set and call our constructor on the left and right set. We continue dividing the bounding boxes until there are less than max_children objects in the current set. A bvh allows us to efficiently prune off objects in the tree that we know do not intersect with our ray when we start raytracing.</p><p>The split method I used was computing the averages of the centroids of each bounding box. I then iterate over each dimension computing the splits in each. So for dimensions<!-- --> <span style="display:inline">\(x, y, z\)</span>, I would get sets<!-- --> <span style="display:inline">\(l, r\)</span>. Then the cost given to the split is:<span style="display:block">\begin{equation*}\text{SA}(l) \cdot \text{l.size}() + \text{SA}(r) \cdot \text{r.size}()\end{equation*}</span>The dimension that gives the lowest cost is chosen. At a high level, this computes the cost of raytracing, as the probability of a ray hitting a box is proportional to the box&#x27;s surface area, and the cost of traversal is equal to the number of items in the box.</p><p>The objects in the bvh were stored in a flat array, and the current objects in our node are represented by a start and end pointer to a continuous segement. So to split, we sort this array similar to inplace quicksorting, then recurse given a left, right partition.</p><p>Finally, here are some renders of scenes with a large number of objects:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="blob default shading with bounding volume hierarchy" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part2/blob.png"/><figcaption> <!-- -->blob<!-- -->, bvh, default shading </figcaption></figure><figure class="text-center w-full"><img alt="blucy default shading with bounding volume hierarchy" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part2/blucy.png"/><figcaption> <!-- -->blucy<!-- -->, bvh, default shading </figcaption></figure><figure class="text-center w-full"><img alt="dragon default shading with bounding volume hierarchy" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part2/dragon.png"/><figcaption> <!-- -->dragon<!-- -->, bvh, default shading </figcaption></figure></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Direct Illumination"><div><h2> Direct Illumination </h2><p>Direct Illumination refers to the incoming light onto a surface from a light source without indirect bounces. When calculating the illumination an object recieves, we consider the angle of the incoming ray, the bsdf function that describes the surface (ratio/distribution of incoming light to outgoing light), and finally, the actual luminous power and color the ray carries.</p><h3> Zero-bounce Illumination </h3><p>In zero-bounce illumination, from a given ray w_in, we would compute the intersection of that ray with our scene. The object that it intersects with gives an emission, which is what I returned from the function.</p><h3> Direct Lighting with Uniform Hemisphere Sampling</h3><p>To implement uniform hemisphere sampling for lighting, I sampled for vectors in the hemisphere of the origin point of the ray. Then for each sample, I compute the ray&#x27;s intersection with the scene, and we can get the illumination by:<span style="display:block">\begin{equation*}\text{isect.bsdf}\rightarrow\text{get_emission()} \cdot \text{cos_theta(w_in)} \cdot \text{bsdf}\rightarrow\text{f(w_out, w_in)}\end{equation*}</span>Here are some examples:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="bunny, uniform sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/uniform/bunny_64_32.png"/><figcaption> <!-- -->bunny<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="coil, uniform sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/uniform/coil_64_32.png"/><figcaption> <!-- -->coil<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="dragon, uniform sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/uniform/dragon_64_32.png"/><figcaption> <!-- -->dragon<!-- --> </figcaption></figure></div><h3> Direct Lighting by Importance Sampling Lights </h3><p>For importance sampling, we iterate over each light and sample from it<!-- --> <span style="display:inline">\(n\)</span> times. After sampling from the light, we set the ray&#x27;s <code>min_t</code> to<!-- --> <code>EPS_F</code> and <code> max_t</code> to<!-- --> <code>distToLight - EPS_F</code> to check if there are any scene objects between the light and surface that would block the light. If not, we compute the illumination similar to above and take the average out of those <span style="display:inline">\(n\)</span> samples. Since we do not sample uniformly, we need to divide our sample by the probability of making that sample. Finally, summing the illumination over all light sources gives us the lighting from importance sampling.</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="bunny, importance sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/importance/bunny_64_32.png"/><figcaption> <!-- -->bunny<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="coil, importance sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/importance/coil_64_32.png"/><figcaption> <!-- -->coil<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="dragon, importance sampling" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/importance/dragon_64_32.png"/><figcaption> <!-- -->dragon<!-- --> </figcaption></figure></div><p>Here is an example of increasing the amount of samples we draw from each light source:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Coil with 1 light samples" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/l_samples/coil_1_1.png"/><figcaption> Coil, light <!-- -->1<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Coil with 4 light samples" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/l_samples/coil_1_4.png"/><figcaption> Coil, light <!-- -->4<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Coil with 16 light samples" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/l_samples/coil_1_16.png"/><figcaption> Coil, light <!-- -->16<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Coil with 64 light samples" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part3/l_samples/coil_1_64.png"/><figcaption> Coil, light <!-- -->64<!-- --> </figcaption></figure></div><p>A difference between uniform sampling and importance sampling would be the amount of noise in the image. With importance sampling, we sample directly from the light source, which allows us to converge faster to the solution. From the images above, the ones obtained from uniform sampling are grainier, with much more variation in the color on each wall compared to importance sampling.</p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Global Illumination"><div><h2> Global Illumination </h2><p>For indirect lighting, we would use a recursive function and trace a ray to a surface. If the ray&#x27;s depth was 1, we would just return the one bounce illumination from the previous part. Otherwise, we sample a ray on the hemisphere, translated to world coordinates, recurse using the function. Since the function returns incoming light, we would multiply by the bsdf and cos_theta for the angle, giving the illumination of the surface.</p><p>This is the illumination where we do not accumulate the illumination from previous bounces:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 0" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M0-NAcc.png"/><figcaption> depth = <!-- -->0<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 1" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M1-NAcc.png"/><figcaption> depth = <!-- -->1<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 2" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M2-NAcc.png"/><figcaption> depth = <!-- -->2<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 3" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M3-NAcc.png"/><figcaption> depth = <!-- -->3<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 4" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M4-NAcc.png"/><figcaption> depth = <!-- -->4<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Luminance with num_ray_bounces = 5" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyNAcc/bunny-M5-NAcc.png"/><figcaption> depth = <!-- -->5<!-- --> </figcaption></figure></div><p> And this is with isAccumBounces enabled:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 0" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M0-Acc.png"/><figcaption> m_depth = <!-- -->0<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 1" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M1-Acc.png"/><figcaption> m_depth = <!-- -->1<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 2" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M2-Acc.png"/><figcaption> m_depth = <!-- -->2<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 3" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M3-Acc.png"/><figcaption> m_depth = <!-- -->3<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 4" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M4-Acc.png"/><figcaption> m_depth = <!-- -->4<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Accumulated bounces with max_ray_depth = 5" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyAcc/bunny-M5-Acc.png"/><figcaption> m_depth = <!-- -->5<!-- --> </figcaption></figure></div><p>When the light is not accumulated, with more bounces, it loses brightness, and this makes sense because the light is scattered when it comes in contact with a surface. When the light is accumulated, the scene becomes brighter, because many areas are more likely to come in contact with light rays when we allow for more bounces.</p><p>We can also split the rendering into direct and indirect lighting. Something interesting to note is that with direct lighting, we get the base color of the object while indirect lighting captures more of the reflective properties of the object:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Dragon rendered with original lighting" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/dragon/dragon-original.png"/><figcaption> <!-- -->original<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Dragon rendered with direct lighting" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/dragon/dragon-direct.png"/><figcaption> <!-- -->direct<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Dragon rendered with indirect lighting" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/dragon/dragon-indirect.png"/><figcaption> <!-- -->indirect<!-- --> </figcaption></figure></div><p>Finally, this shows spheres rendered with a varying number of samples-per-pixel:</p><div class="grid grid-cols-4 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Spheres rendered with 1 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S1.png"/><figcaption> <!-- -->1<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 2 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S2.png"/><figcaption> <!-- -->2<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 4 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S4.png"/><figcaption> <!-- -->4<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 8 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S8.png"/><figcaption> <!-- -->8<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 16 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S16.png"/><figcaption> <!-- -->16<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 64 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S64.png"/><figcaption> <!-- -->64<!-- --> spp </figcaption></figure><figure class="text-center w-full"><img alt="Spheres rendered with 1024 samples per pixel" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/spheres/spheres-S1024.png"/><figcaption> <!-- -->1024<!-- --> spp </figcaption></figure></div><h2> Russian Roulette </h2><p>Computing the global illumination requires us to sum over all the<!-- --> <span style="display:inline">\(k\)</span>-bounces of light through a scene for <span style="display:inline">\(k \geq 0\)</span>. An unbiased solution to this problem involves flipping a coin with weight<!-- --> <span style="display:inline">\(cpdf\)</span> to check whether the ray should continue bouncing. If it does, we calculate the incoming light and divide that additionally by the<!-- --> <span style="display:inline">\(cpdf\)</span>. If not, we return the one bounce illumination function as the base case.</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 0" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M0-RR.png"/><figcaption> m_depth = <!-- -->0<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 1" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M1-RR.png"/><figcaption> m_depth = <!-- -->1<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 2" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M2-RR.png"/><figcaption> m_depth = <!-- -->2<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 3" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M3-RR.png"/><figcaption> m_depth = <!-- -->3<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 4" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M4-RR.png"/><figcaption> m_depth = <!-- -->4<!-- --> </figcaption></figure><figure class="text-center w-full"><img alt="Russian roulette bunny scene with max_ray_depth = 100" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part4/bunnyRR/bunny-M100-RR.png"/><figcaption> m_depth = <!-- -->100<!-- --> </figcaption></figure></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Adaptive Sampling"><div><h2>Adaptive Sampling</h2><p>In adaptive sampling, we check that the margin of error is less than a given tolerance. So given <span style="display:inline">\(n\)</span> <!-- -->samples, I calculated the illumination of the sample, the average illumination and variance of illumination. Then<!-- --> <span style="display:block">\begin{equation*}I = 1.96 \cdot \sqrt{\frac{\sigma^2}{n}}\end{equation*}</span>and I checked for every <span style="display:inline">\(32\)</span> <!-- -->samples if<!-- --> <span style="display:inline">\(I \leq maxTolerance \cdot \mu \)</span> <!-- -->which would be the condition to stop. Here are some results:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><div><figure class="text-center undefined"><img alt="Adaptive sampling of bunny" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/bunny-adp.png"/><figcaption> <!-- -->bunny<!-- --> S=2048 M=5 </figcaption></figure><figure class="text-center undefined"><img alt="Adaptive sampling rate of bunny" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/bunny-adp_rate.png"/><figcaption> <!-- -->bunny<!-- --> sampling rate </figcaption></figure></div><div><figure class="text-center undefined"><img alt="Adaptive sampling of coil" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/coil-adp.png"/><figcaption> <!-- -->coil<!-- --> S=2048 M=5 </figcaption></figure><figure class="text-center undefined"><img alt="Adaptive sampling rate of coil" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/coil-adp_rate.png"/><figcaption> <!-- -->coil<!-- --> sampling rate </figcaption></figure></div><div><figure class="text-center undefined"><img alt="Adaptive sampling of dragon" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/dragon-adp.png"/><figcaption> <!-- -->dragon<!-- --> S=2048 M=5 </figcaption></figure><figure class="text-center undefined"><img alt="Adaptive sampling rate of dragon" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="zoom-in w-full text-center" style="color:transparent" src="/projects/ComputerGraphics/Project3/media/part5/dragon-adp_rate.png"/><figcaption> <!-- -->dragon<!-- --> sampling rate </figcaption></figure></div></div><p>With adaptive sampling, parts of the scene that are not directly visible to the light are sampled more. For instance, the shadow of the bunny and coil are red, while the walls are blue.</p></div></article></div></section></div><div class="block flex-grow max-w-[25%]"><div class="max-w-[80%] mx-auto h-full"><div class="sticky top-[20%] p-4 pl-6 border-1 border-black border-solid rounded-[1rem] bg-black shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-auto  max-h-[60vh] overflow-y-auto "><nav><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Overview">Overview</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Ray Generation and Scene Intersection">Ray Generation and Scene Intersection</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Bounding Volume Hierarchy">Bounding Volume Hierarchy</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Direct Illumination">Direct Illumination</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Global Illumination">Global Illumination</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Adaptive Sampling">Adaptive Sampling</a></ul></nav></div></div></div></div></div></div></div><footer class="w-full bg-black text-center p-4 text-white shadow-[0_-5px_15px_rgba(0,0,0,0.35)]"><div>&lt;&lt;&lt; © Trustin Nguyen &gt;&gt;&gt;</div><div><a class="text-white hover:text-gray-300 hover:scale-100 focus:text-gray-300 focus:scale-100" href="#"> <!-- -->Back to Top<!-- --> </a></div></footer></div><script src="/_next/static/chunks/webpack-9edee2920554d0a5.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[4547,[],\"ClientSegmentRoot\"]\n3:I[7249,[\"173\",\"static/chunks/173-ef7ddebb9db08982.js\",\"795\",\"static/chunks/795-77b345457a57fcf5.js\",\"177\",\"static/chunks/app/layout-98844b15afe18919.js\"],\"default\"]\n4:I[5244,[],\"\"]\n5:I[3866,[],\"\"]\n7:I[7033,[],\"ClientPageRoot\"]\n8:I[5624,[\"173\",\"static/chunks/173-ef7ddebb9db08982.js\",\"795\",\"static/chunks/795-77b345457a57fcf5.js\",\"970\",\"static/chunks/970-ed0831cff5c90225.js\",\"409\",\"static/chunks/app/projects/ComputerGraphics/Project3/page-42c309db0f3cd646.js\"],\"default\"]\nb:I[6213,[],\"OutletBoundary\"]\nd:I[6213,[],\"MetadataBoundary\"]\nf:I[6213,[],\"ViewportBoundary\"]\n11:I[4835,[],\"\"]\n:HL[\"/_next/static/css/d60010527bb7432e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"JfcN7-uTu9p_3a7XOwIiK\",\"p\":\"\",\"c\":[\"\",\"projects\",\"ComputerGraphics\",\"Project3\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"ComputerGraphics\",{\"children\":[\"Project3\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d60010527bb7432e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"Component\":\"$3\",\"slots\":{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]},\"params\":{},\"promise\":\"$@6\"}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"ComputerGraphics\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ComputerGraphics\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"Project3\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ComputerGraphics\",\"children\",\"Project3\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L7\",null,{\"Component\":\"$8\",\"searchParams\":{},\"params\":\"$0:f:0:1:1:props:children:1:props:params\",\"promises\":[\"$@9\",\"$@a\"]}],null,[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"uVPuxnjJXcRzmGjnmVWDt\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n9:{}\na:{}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script></body></html>