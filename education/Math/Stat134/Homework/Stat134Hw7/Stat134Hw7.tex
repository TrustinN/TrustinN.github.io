%! TeX root = /Users/trustinnguyen/Downloads/Berkeley/Math/Stat134/Homework/Stat134Hw7/Stat134Hw7.tex

\documentclass{article}
\usepackage{/Users/trustinnguyen/.mystyle/math/packages/mypackages}
\usepackage{/Users/trustinnguyen/.mystyle/math/commands/mycommands}
\usepackage{/Users/trustinnguyen/.mystyle/math/environments/article}
\graphicspath{{./figures/}}

\title{Stat134Hw7}
\author{Trustin Nguyen}

\begin{document}

    \maketitle

\reversemarginpar

\textbf{Exercise 1}: Suppose that $\mathcal{L}$ is a continuous random variable with the Laplace distribution of density
    \begin{equation*}
        f(x) = \dfrac{1}{2}e^{-\lvert x \rvert}, \, x \in \mathbb{R}
    \end{equation*}
Find the moment generating function of $\mathcal{L}$ and use it to compute the variance of $\mathcal{L}$.
    \begin{answer}
        By definition:
            \begin{equation*}
                M_{\mathcal{L}}(t) = \mathbb{E}e^{t\mathcal{L}} = \int_{-\infty}^{\infty} \dfrac{1}{2}e^{-\lvert x \rvert}e^{tx} \, \dd{x} 
            \end{equation*}
        Then we have:
            \begin{equation*}
                \int_{-\infty}^{0} \dfrac{1}{2}e^{-\lvert x \rvert + tx} \, \dd{x}  + \int_{0}^{\infty} \dfrac{1}{2} e^{-\lvert x \rvert + tx} \, \dd{x} 
            \end{equation*}
        On the negative values, $\lvert x \rvert = -x$ and for positive, $\lvert x \rvert = x$. So:
            \begin{equation*}
                \int_{-\infty}^{0} \dfrac{1}{2}e^{x + tx} \, \dd{x}  + \int_{0}^{\infty} \dfrac{1}{2}e^{-x + tx} \, \dd{x} 
            \end{equation*}
        So we have:
            \begin{equation*}
                \dfrac{1}{2}\left(\left(\dfrac{e^{x(t + 1)}}{t + 1}\right)\eval_{-\infty}^{0} + \left(\dfrac{e^{x(t - 1)}}{t - 1}\right)\eval_{0}^{\infty}\right)
            \end{equation*}
        When we evaluate the limit $\lim\limits_{x \to -\infty} e^{x(t + 1)}$, we require that the exponent is negative, so that gives the restriction $-1 < t$. For the other summand, we require $t < 1$ for the same reason. So after evaluation:
            \begin{equation*}
                \dfrac{1}{2}\left(\dfrac{1}{t + 1} - \dfrac{1}{t - 1}\right) = \dfrac{1}{2}\left(\dfrac{t - 1}{t^{2} - 1} - \dfrac{t + 1}{t^{2} - 1}\right)
            \end{equation*}
        which is 
            \begin{equation*}
                \dfrac{1}{2}\left(\dfrac{-2}{t^{2} - 1}\right) = -\dfrac{1}{t^{2} - 1}
            \end{equation*}
        for $-1 < t < 1$.
    \end{answer}

\newpage

\textbf{Exercise 2}: In this problem you are given MGF $M_{X}(t) = \mathbb{E}e^{tX}$ of a discrete random variable $X$ and your task is to find the probability mass function of $X$:
    \begin{itemize}
        \item [(a)] $M_{X}(t) = \frac{4}{7}\left(1 + \frac{1}{2}e^{-t} + \frac{1}{4}e^{-2t}\right)$.
            \begin{answer}
                Multiply out:
                    \begin{equation*}
                        M_{X}(t) = \dfrac{4}{7}e^{(0) t} + \dfrac{2}{7}e^{(-1)t} + \dfrac{1}{7}e^{(-2)t}
                    \end{equation*}
                This is the formula for the expectation, so we can recover the pmf:
                    \begin{align*}
                        p_{X}(0)  &= \dfrac{4}{7} \\
                        p_{X}(-1) &= \dfrac{2}{7} \\
                        p_{X}(-2) &= \dfrac{1}{7}   
                    \end{align*}
                Since the MGF uniquely determines the distribution, this defines $p_{X}(x)$ fully.
            \end{answer}

        \item [(b)] $M_{X}(t) = \frac{1}{9}\left(1 + e^{t} + e^{2t}\right)^{2}$.
            \begin{answer}
                Expand:
                    \begin{align*}
                        M_{X}(t) &= \dfrac{1}{9}(1 + e^{t} + e^{2t} + e^{t} + e^{2t} + e^{3t} + e^{2t} + e^{3t} + e^{4t}) \\
                                 &= \dfrac{1}{9}(1 + 2e^{t} + 3e^{2t} + 2e^{3t} + e^{4t}) \\
                                 &= \dfrac{1}{9}e^{0t} + \dfrac{2}{9}e^{1t} + \dfrac{1}{3}e^{2t} + \dfrac{2}{9}e^{3t} + \dfrac{1}{9}e^{4t}
                    \end{align*}
                So again we can uniquely recover the pmf:
                    \begin{align*}
                        p_{X}(0) &= \dfrac{1}{9} \\
                        p_{X}(1) &= \dfrac{2}{9} \\
                        p_{X}(2) &= \dfrac{1}{3} \\
                        p_{X}(3) &= \dfrac{2}{9} \\
                        p_{X}(4) &= \dfrac{1}{9}   
                    \end{align*}
            \end{answer}

        \item [(c)] $M_{X}(t) = \frac{1}{2 - e^{-t}}$ 
            \begin{answer}
                We see that:
                    \begin{equation*}
                        M_{X}(t) = \dfrac{1}{1 - \frac{e^{-t}}{2}} = \sum_{n \geq 0} (e^{-t}/2)^{n} = \sum_{n \geq 0} \dfrac{1}{2^{n}}e^{-tn}
                    \end{equation*}
                So we see that:
                    \begin{equation*}
                        p_{X}(x) = \begin{cases}
                            \dfrac{1}{2^{x}} &\text{ if } x \in \mathbb{Z}_{\geq 0} \\
                            0 &\text{ if } otherwise          
                        \end{cases}
                    \end{equation*}
            \end{answer}
    \end{itemize}

\newpage

\textbf{Exercise 3}: Find the marginal distribution of random variable $Y$, if the joint pmf of $(X, Y)$ is:
    \begin{center}
        \begin{tabular}{ c c c c }
            \hline X $\backslash$ Y & 1    & 2    & 3   \\
            \hline 0    & 1/21 & 2/21 & 1/7 \\
            \hline 1    & 4/21 & 5/21 & 2/7   
        \end{tabular}
    \end{center}
which are values of $P(X = k, Y = m)$.
    \begin{answer}
        The marginal distribution is would be fixing each $Y$ value and varying over probabilities of $X$:
            \begin{align*}
                P_{Y}(1) &= \dfrac{1}{21} + \dfrac{4}{21} \\
                P_{Y}(2) &= \dfrac{2}{21} + \dfrac{5}{21} \\
                P_{Y}(3) &= \dfrac{1}{7} + \dfrac{2}{7}     
            \end{align*}
        so
            \begin{align*}
                P_{Y}(1) &= \dfrac{5}{21} \\
                P_{Y}(2) &= \dfrac{1}{3}  \\
                P_{Y}(3) &= \dfrac{3}{7}    
            \end{align*}
    \end{answer}

\newpage

\textbf{Exercise 4}: Recall that the addition mod $2$ is defined by the rules:
    \begin{equation*}
        0 + 0 \equiv 0 \pmod{2}, \, 0 + 1 \equiv 1 \pmod{2}, \, 1 + 0 \equiv 1 \pmod{2}, \, 1 + 1 \equiv 0 \pmod{2}
    \end{equation*}
let $X$ and $Y$ be two independent Bernoulli random variables with $P(X = 0) = P(X = 1) = P(Y = 0) = P(Y = 1) = \frac{1}{2}$, and let $Z = X + Y \pmod{2}$. 
    \begin{itemize}
        \item [(a)] Compute the joint probability mass function of $X, Y, Z$.
            \begin{answer}
                To calculate the joint pmf, we first calculate the pmf of $Z$:
                    \begin{align*}
                        P_{Z}(0) &= P(X = 0, Y = 0) + P(X = 1, Y = 1) = \dfrac{1}{2} \\
                        P_{Z}(1) &= P(X = 1, Y = 0) + P(X = 0, Y = 1) = \dfrac{1}{2}
                    \end{align*}
                We immediately see that:
                    \begin{align*}
                        P(X = 0, Y = 1, Z = 0) &= 0 \\
                        P(X = 1, Y = 0, Z = 0) &= 0 \\
                        P(X = 0, Y = 0, Z = 1) &= 0 \\
                        P(X = 1, Y = 1, Z = 1) &= 0   
                    \end{align*}
                What is left are the four cases:
                    \begin{align*}
                        P(X = 0, Y = 1, Z = 1) &= ? \\
                        P(X = 1, Y = 0, Z = 1) &= ? \\
                        P(X = 0, Y = 0, Z = 0) &= ? \\
                        P(X = 1, Y = 1, Z = 0) &= ?   
                    \end{align*}
                But we know that the probability of $Z = 0$ or $1$ is $1$ given that $X, Y$ are a certain value. So $Z$ is completely dependent on $X, Y$, we can simplify:
                    \begin{align*}
                        P(X = 0, Y = 1, Z = 1) &= P(X = 0, Y = 1) = 1/4 \\
                        P(X = 1, Y = 0, Z = 1) &= P(X = 1, Y = 0) = 1/4 \\
                        P(X = 0, Y = 0, Z = 0) &= P(X = 0, Y = 0) = 1/4 \\
                        P(X = 1, Y = 1, Z = 0) &= P(X = 1, Y = 1) = 1/4   
                    \end{align*}
            \end{answer}

        \item [(b)] Show that $(Y, Z)$ are independent, but $(X, Y, Z)$ are not independent. 
            \begin{answer}
                We see that $(X, Y, Z)$ is not independent because
                    \begin{equation*}
                        P(X = 0, Y = 1, Z = 0) = 0 \neq P(X = 0)P(Y = 1)P(Z = 0) = 1/8
                    \end{equation*}
                To get $(Y, Z)$, we fix instances of $Y, Z$ and add up the variation among $X$:
                    \begin{align*}
                        P(Y = 0, Z = 0) &= P(X = 0, Y = 0, Z = 0) + P(X = 1, Y = 0, Z = 0) \\
                        P(Y = 0, Z = 1) &= P(X = 0, Y = 0, Z = 1) + P(X = 1, Y = 0, Z = 1) \\
                        P(Y = 1, Z = 0) &= P(X = 0, Y = 1, Z = 0) + P(X = 1, Y = 1, Z = 0) \\
                        P(Y = 1, Z = 1) &= P(X = 0, Y = 1, Z = 1) + P(X = 1, Y = 1, Z = 1)   
                    \end{align*}
                We see that all these sums are $1/4$ and they obey they product rule for independence:
                    \begin{equation*}
                        P(Y = a)P(Z = b) = P(Y = a, Z = b)
                    \end{equation*}
            \end{answer}
    \end{itemize}

\newpage

\textbf{Exercise 5}: Sisters Anna and Mary bought a box with four individually wrapped chocolate truffles. On Monday and Tuesday, Anna was coming home very hungry. Each day she was flipping a fair coin. If it comes heads, Anna eats one chocolate truffle and replaces it with a fake plastic truffle in the same wrapping. On Wednesday Mary took two random truffles out of the four in the box. Let $X$ be the total number of truffles Anna ate and let $Y$ be the number of true (rather than fake plastic ones) truffles which Mary took.
    \begin{itemize}
        \item [(a)] Find the joint probability mass function of $X$ and $Y$.
            \begin{answer}
                Make a table:
                    \begin{align*}
                        \begin{array}{ c c c c c }
                            X \backslash Y & 0 & 1 & 2 & sum    \\
                            0              & 1/4 & 0 & 0 & 1/4 \\
                            1              & ? & ? & 0 & 2/4 \\
                            2              & ? & ? & ? & 1/4   
                        \end{array}
                    \end{align*}
                
            \end{answer}

        \item [(b)] Find $\mathbb{E}Y$.
    \end{itemize}




\end{document}
